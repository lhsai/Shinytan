---
title: "ShinyStan Automated Diagnostics Report"
output:
  html_document: 
    toc: TRUE
    toc_float: 
      collapsed: FALSE
      depth: 3
  pdf_document: 
    toc: TRUE
  word_document: 
    toc: TRUE
date: "`r format(Sys.time(), '%d %B %Y, %H:%M')`"
fontsize: 11pt
---


```{r global_options, include=FALSE}
# Within the function generate_report the shinystan object (sso) is prepared for this markdown file.
# The following can be used to prepare the sso for use with this markdown file.
# nopars is a logical value that describes if the pars argument has been used.
#
# if(nopars){
#   selected_parameters <- sso@param_names[order(sso@summary[, "n_eff"])] 
#   selected_parameters <- selected_parameters[-which(selected_parameters == "log-posterior")]
#   
#   if(n_param == "all") n_param <- length(selected_parameters)
#   if(n_param > length(selected_parameters)) n_param <- length(selected_parameters)
#   sso <- drop_parameters(sso, pars = selected_parameters[-c(1:n_param)])
# } else {
#   selected_parameters <- sso@param_names[order(sso@summary[, "n_eff"])] 
#   selected_parameters <- selected_parameters[-which(selected_parameters == "log-posterior")]
#   selected_parameters <- c(pars, selected_parameters[-which(selected_parameters %in% pars)])
#   n_param <- length(pars)
#   sso <- drop_parameters(sso, pars = selected_parameters[-which(selected_parameters %in% pars)])
# }
# 

library(dplyr)
library(bayesplot)

knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, comment = "  ")
showplots <- FALSE

printf <- function(msg = "%5.3f", ...) {
  cat(sprintf(msg, ...))
}


```

# Warnings

```{r}

divergences <- sum(nuts_params(sso@sampler_params %>%
                   lapply(., as.data.frame) %>%
                   lapply(., filter, row_number() > sso@n_warmup) %>%
                   lapply(., as.matrix), 
                   pars = "divergent__")[, 3]) != 0



if(divergences) {
  lapply(sso@sampler_params, "[", , "divergent__") %>%
    lapply(., as.data.frame) %>%
    lapply(., filter, row_number() > sso@n_warmup) %>%
    lapply(., function (x) x > 0 ) %>% lapply(., sum) %>% 
    unlist(.) %>% sum(.) %>%
    paste0(., " of ", (sso@n_iter-sso@n_warmup) * sso@n_chain,
           " iterations ended with a divergence (",
           round((. / ((sso@n_iter-sso@n_warmup) * sso@n_chain)) * 100, 1),
           "%).")
} else {
  print(paste0("None of the ", (sso@n_iter-sso@n_warmup) * sso@n_chain, 
               " iterations ended with a divergent transition."))
}



```

\newpage

# Numerical diagnostics


```{r diagnostics_table}
round(sso@summary, 2)[c("log-posterior", selected_parameters[1:n_param]), c("n_eff", "Rhat",
                                                                   "mean", "se_mean", "sd")]
```

\newpage

# Visual diagnostics

## Divergence Information

These are plots of the *divergent transition status* (x-axis) against the *log-posterior* (y-axis top panel) and against the *acceptance statistic* (y-axis bottom panel) of the sampling algorithm for all chains. Divergent transitions can indicate problems for the validity of the results. A good plot would show no divergent transitions. If the divergent transitions show the same pattern as the non divergent transitions, this could indicate that the divergent transitions are false positives. A bad plot would shows systematic differences between the divergent transitions and non-divergent transitions. For more information see [https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup](https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup).

```{r divergence_transition_plot}
mcmc_nuts_divergence(
  x = nuts_params(sso@sampler_params %>%
                    lapply(., as.data.frame) %>%
                    lapply(., filter, row_number() > sso@n_warmup) %>%
                    lapply(., as.matrix)),
  lp = data.frame(Iteration = rep(1:(sso@n_iter - sso@n_warmup), sso@n_chain),
                  Value = c(sso@posterior_sample[(sso@n_warmup + 1):sso@n_iter, ,"log-posterior"]),
                  Chain = rep(1:sso@n_chain, each = (sso@n_iter - sso@n_warmup))) 
)
``` 

\newpage

## Energy

These are plots of the overlaid histograms of the marginal energy distribution ($\pi_E$) and the energy transition distribution ($\pi_{\Delta E}$) for all chains. A good plot shows histograms that look well-matched indicating that the Hamiltonian Monte Carlo should perform robustly. The closer   $\pi_{\Delta E}$ is to $\pi_E$ the faster the random walk explores the energies and the smaller the autocorrelations will be in the chain. If  $\pi_{\Delta E}$ is narrower than $\pi_E$ the random walk is less effective and autocorrelations will be larger. Additionally the chain may not be able to completely explore the tails of the target distribution. See Betancourt ['A conceptual introduction to Hamiltonian Monte Carlo'](https://arxiv.org/abs/1701.02434) and Betancourt ['Diagnosing suboptimal cotangent disintegrations in Hamiltonian Monte Carlo'](https://arxiv.org/abs/1604.00695) for the general theory behind the energy plots. 

```{r energy_plot}
mcmc_nuts_energy(
  nuts_params(sso@sampler_params %>%
                lapply(., as.data.frame) %>%
                lapply(., filter, row_number() > sso@n_warmup) %>%
                lapply(., as.matrix)
              ) 
)

``` 

\newpage

## Treedepth Information

These are plots of the *treedepth* (x-axis) against the *log-posterior* (y-axis top left panel) and against the *acceptance statistic* (y-axis top right panel) of the sampling algorithm for all chains. In these plots information is given concerning the efficiency of the sampling algorithm. Zero treedepth can indicate extreme curvature and poorly-chosen step size. Treedepth equal to the maximum treedepth might be a sign of poor adaptation or of a difficult posterior from which to sample. The former can be resolved by increasing the warmup time, the latter might be mitigated by reparametrization. For more information see [https://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded](https://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded) or [https://mc-stan.org/docs/reference-manual/hmc-algorithm-parameters.html](https://mc-stan.org/docs/2_19/reference-manual/hmc-algorithm-parameters.html).


```{r treedepth_plot}
mcmc_nuts_treedepth(
  x = nuts_params(sso@sampler_params %>%
                    lapply(., as.data.frame) %>%
                    lapply(., filter, row_number() > sso@n_warmup) %>%
                    lapply(., as.matrix)),
  lp = data.frame(Iteration = rep(1:(sso@n_iter - sso@n_warmup), sso@n_chain),
                  Value = c(sso@posterior_sample[(sso@n_warmup + 1):sso@n_iter, ,"log-posterior"]),
                  Chain = rep(1:sso@n_chain, each = (sso@n_iter - sso@n_warmup))) 
)

``` 


\newpage

## Step Size Information

These are plots of the *integrator step size per chain* (x-axis) against the *log-posterior* (y-axis top panel) and against the *acceptance statistic* (y-axis bottom panel) of the sampling algorithm. If the step size is too large, the integrator will be inaccurate and too many proposals will be rejected. If the step size is too small, the many small steps lead to long simulation times per interval. Thus the goal is to balance the acceptance rate between these extremes. Good plots will show full exploration of the log-posterior and moderate to high acceptance rates for all chains and step sizes. Bad plots might show incomplete exploration of the log-posterior and lower acceptance rates for larger step sizes.

```{r stepsize_plot}
mcmc_nuts_stepsize(
  x = nuts_params(sso@sampler_params %>%
                    lapply(., as.data.frame) %>%
                    lapply(., filter, row_number() > sso@n_warmup) %>%
                    lapply(., as.matrix)),
  lp = data.frame(Iteration = rep(1:(sso@n_iter - sso@n_warmup), sso@n_chain),
                  Value = c(sso@posterior_sample[(sso@n_warmup + 1):sso@n_iter, ,"log-posterior"]),
                  Chain = rep(1:sso@n_chain, each = (sso@n_iter - sso@n_warmup))) 
)
``` 


\newpage

## Acceptance Information

These are plots of the *acceptance statistic* (top leftpanel), the *log-posterior* (top right panel), and, the *acceptance statistic* (x-axis bottom panel) against the *log-posterior* (y-axis bottom panel) for all chains. The vertical lines indicate the mean (solid line) and median (dashed line). A bad plot would show a relationship between the acceptance statistic and the log-posterior. This might be indicative of poor exploration of parts of the posterior which might be might be mitigated by reparametrization or adaptation of the step size. If many proposals are rejected the integrator step size might be too large and the posterior might not be fully explored. If the acceptance rate is very high this might be indicative of inefficient sampling. The target Metropolis acceptance rate can be set with the `adapt_delta` control option. For more information see [https://mc-stan.org/docs/reference-manual/hmc-algorithm-parameters.html](https://mc-stan.org/docs/reference-manual/hmc-algorithm-parameters.html).


```{r acceptance_plot}
mcmc_nuts_acceptance(
  x = nuts_params(sso@sampler_params %>%
                    lapply(., as.data.frame) %>%
                    lapply(., filter, row_number() > sso@n_warmup) %>%
                    lapply(., as.matrix)),
  lp = data.frame(Iteration = rep(1:(sso@n_iter - sso@n_warmup), sso@n_chain),
                  Value = c(sso@posterior_sample[(sso@n_warmup + 1):sso@n_iter, ,"log-posterior"]),
                  Chain = rep(1:sso@n_chain, each = (sso@n_iter - sso@n_warmup))) 
)
```

\newpage

## Scatter plots

These are scatter plots of `r if(nopars == FALSE){selected_parameters}``r if(nopars){paste0("the ", n_param, " worst performing parameters in terms of n_eff")}`, plotted against  `log-posterior`. The red dots, if present, indicate divergent transitions. Divergent transitions can indicate problems for the validity of the results. A good plot would show no divergent transitions. A bad plot would show divergent transitions in a systematic pattern. For more information see [https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup](https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup).


```{r diverget_scatter_plot, out.width = '45%', fig.show = 'hold'}

for(i in 1:n_param) {
  parameters <- c(selected_parameters[i], "log-posterior")
  print(mcmc_scatter(
    sso@posterior_sample[(1 + sso@n_warmup) : sso@n_iter, , ],
    pars = parameters,
    alpha = .7,
    np = nuts_params(sso@sampler_params %>%
                    lapply(., as.data.frame) %>%
                    lapply(., filter, row_number() > sso@n_warmup) %>%
                    lapply(., as.matrix)),
    np_style = scatter_style_np(div_color = "red", div_alpha = .7)
  ))
}

```

\newpage

## Autocorrelation

These are autocorrelation plots of `r if(nopars == FALSE){selected_parameters}``r if(nopars){paste0("the ", n_param, " worst performing parameters in terms of n_eff")}`. The autocorrelation expresses the dependence between the samples of a Monte Carlo simulation. With higher dependence between the draws, more samples are needed to obtain the same effective sample size. High autocorrelation can sometimes be remedied by reparametrization of the model.

```{r autocorrelation_plot, out.width = '45%', fig.show = 'hold'}

for(i in 1:n_param) {
  parameters <- c(selected_parameters[i])
  print(
    mcmc_acf_bar( sso@posterior_sample[(1 + sso@n_warmup) : sso@n_iter, , ], 
              pars = parameters,
              lags = 20
    )
  )
}

```


\newpage

## Trace Plots

These are trace plots of `r if(nopars == FALSE){selected_parameters}``r if(nopars){paste0("the ", n_param, " worst performing parameters in terms of n_eff")}`, for all chains. Trace plots provide a visual way to inspect sampling behavior and assess mixing across chains. The iteration number (x-axis) is plotted against the parameter value at that iteration (y-axis). Divergent transitions are marked on the x-axis. A good plot shows chains that move swiftly through the parameter space and all chains that explore the same parameter space without any divergent transitions. A bad plot shows chains exploring different parts of the parameter space, this is a sign of non-convergence. If there are divergent transitions, looking at the parameter value related to these iterations might provide information about the part of the parameter space that is difficult to sample from. Slowly moving chains are indicative of high autocorrelation or small integrator step size, both of which relate to ineffective sampling and lower effective sample sizes for the parameter.


```{r trace_plot, out.width = '45%', fig.show = 'hold'}

for(i in 1:n_param) {
  parameters <- c(selected_parameters[i])
  print(
    mcmc_trace( 
      sso@posterior_sample[(1 + sso@n_warmup) : sso@n_iter, , ], 
      pars = parameters,
      np = nuts_params(sso@sampler_params %>%
                         lapply(., as.data.frame) %>%
                         lapply(., filter, row_number() > sso@n_warmup) %>%
                         lapply(., as.matrix)),
      np_style = scatter_style_np(div_color = "red", div_size = .25)
    )
    
  )
}

```

\newpage

## Rank Plots

These are rank plots of `r if(nopars == FALSE){selected_parameters}``r if(nopars){paste0("the ", n_param, " worst performing parameters in terms of n_eff")}`, for all chains. Rank histograms visualize how the values from the chains mix together in terms of ranking. An ideal plot would show the rankings mixing or overlapping in a uniform distribution. See [Vehtari et al. (2019)](https://arxiv.org/abs/1903.08008) for details.

```{r rank_plot, fig.height = 3, fig.show = 'hold'}

for(i in 1:n_param) {
  parameters <- c(selected_parameters[i])
  print(
    mcmc_rank_hist( 
      sso@posterior_sample[(1 + sso@n_warmup) : sso@n_iter, , ], 
      pars = parameters
    ) 
  )
}

```

\newpage

# Model Code

```{r model_code}
if(object.size(sso@model_code) < 8000){
  printf(sso@model_code)
} else {
  print(sso@model_code)
}
```